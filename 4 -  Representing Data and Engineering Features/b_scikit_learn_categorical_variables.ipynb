{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneHotEncoder and ColumnTransformer: Categorical Variables with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, scikit-learn can also perform one-hot-encoding. Using scikit-learn has the advantage of making it easy to treat training and test set in a consistent way. One-hot-encoding is implemented in the *OneHotEncoder* class.  Notably, the *OneHotEncoder* applies the encoding to all input columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "from IPython.display import display\n",
    "import mglearn\n",
    "\n",
    "# Don't display deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df = pd.DataFrame({'Integer Feature': [0, 1, 2, 1],\n",
    "                        'Categorical Feature': ['socks', 'fox', 'socks', 'box']})\n",
    "demo_df['Integer Feature'] = demo_df['Integer Feature'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Setting sparse=False means OneHotEncode will return a numpy array,\n",
    "# not a sparse matrix\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "print(ohe.fit_transform(demo_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that both the string and integer feature were transformed. As usual for scikit-learn, the output is not a DataFrame, so there are no column names. To obtain the correspondence of the transformed features to the original categorical variables, we can use the *get_feature_names* method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x0_0' 'x0_1' 'x0_2' 'x1_box' 'x1_fox' 'x1_socks']\n"
     ]
    }
   ],
   "source": [
    "print(ohe.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There, the first three columns correspond to the values 0, 1, and 2 of the first original feature (called x0 here), while the last three columns correspond to the values box, fox, and socks for the second original feature (called x1 here).\n",
    "\n",
    "In most applications, some features are categorical and some are continuous, so *OneHotEncoder* is not directly applicable, as it assumes all features are categorical. This is where the *ColumnTransformer* class comes in handy: it allows you to apply different transformations to different columns in the input data. This is incredibly useful, since continuous and categorical features need very different kinds of preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s go back to the example of the adult census data we considered earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>occupation</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Male</td>\n",
       "      <td>13</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education   gender  hours-per-week  \\\n",
       "0   39          State-gov   Bachelors     Male              40   \n",
       "1   50   Self-emp-not-inc   Bachelors     Male              13   \n",
       "2   38            Private     HS-grad     Male              40   \n",
       "3   53            Private        11th     Male              40   \n",
       "4   28            Private   Bachelors   Female              40   \n",
       "\n",
       "           occupation  income  \n",
       "0        Adm-clerical   <=50K  \n",
       "1     Exec-managerial   <=50K  \n",
       "2   Handlers-cleaners   <=50K  \n",
       "3   Handlers-cleaners   <=50K  \n",
       "4      Prof-specialty   <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "adult_path = os.path.join(mglearn.datasets.DATA_PATH, \"adult.data\")\n",
    "data = pd.read_csv(\n",
    "    adult_path, header=None, index_col=False,\n",
    "    names=['age', 'workclass', 'fnlwgt', 'education',  'education-num',\n",
    "           'marital-status', 'occupation', 'relationship', 'race', 'gender',\n",
    "           'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
    "           'income'])\n",
    "\n",
    "data = data[['age', 'workclass', 'education', 'gender', 'hours-per-week',\n",
    "             'occupation', 'income']]\n",
    "\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply, say, a linear model to this dataset to predict income, in addition to applying one-hot-encoding to the categorical variables, we might also want to scale the continuous variables age and hours-per-week. This is exactly what *ColumnTransformer* can do for us. \n",
    "\n",
    "Each transformation in the column transformer is specified by a name (we will see later why this is useful), a transformer object, and the columns this transformer should be applied to. The columns can be specified using column names, integer indices, or boolean masks. Each transformer is applied to the corresponding columns, and the result of the transformations are concatenated (horizontally). For the example earlier, using column names the specification looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [(\"scaling\", StandardScaler(), ['age', 'hours-per-week']),\n",
    "     (\"onehot\", OneHotEncoder(sparse=False), ['workclass', 'education', 'gender', 'occupation'])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the *ColumnTransformer* object as we would any other scikit-learn transformation, using fit and transform. So let’s build a linear model as before, but this time include scaling of the continuous variables. Note that we are calling *train_test_split* on the DataFrame containing the features, not on a NumPy array. We need to preserve the column names so that they can be used in the ColumnTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24420, 44)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get all columns apart from income for the features\n",
    "data_features = data.drop(\"income\", axis=1)\n",
    "\n",
    "# Split dataframe and income\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_features, data.income, random_state=0)\n",
    "\n",
    "ct.fit(X_train)\n",
    "X_train_trans = ct.transform(X_train)\n",
    "\n",
    "print(X_train_trans.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that we obtained 44 features, the same as when we used pd.get_dummies before, except that we also scaled the continuous features. Now we can build a LogisticRegression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.81\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_trans, y_train)\n",
    "\n",
    "X_test_trans = ct.transform(X_test)\n",
    "print(\"Test score: {:.2f}\".format(logreg.score(X_test_trans, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, scaling the data didn’t make a difference, but encapsulating all of the preprocessing inside a transformer has additional benefits that we will discuss later. You can access the steps inside the *ColumnTransformer* via the *named_transformers_* attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "       n_values=None, sparse=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.named_transformers_.onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convenient ColumnTransformer creation with make_columntransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a ColumnTransformer using the syntax described earlier is sometimes a bit cumbersome, and we often don’t need user-specified names for each step. There is a convenience function (*make_columntransformer*) that will create a ColumnTranformer for us and automatically name each step based on its class. The syntax for *make_columntransformer* is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "ct = make_column_transformer(\n",
    "    (['age', 'hours-per-week'], StandardScaler()),\n",
    "    (['workclass', 'education', 'gender', 'occupation'], OneHotEncoder(sparse=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A disadavantage of using the *ColumnTransformer* is that in version 0.20 it is not yet possible to readily find which input columns correspond to which output columns of the column transformer in all cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
